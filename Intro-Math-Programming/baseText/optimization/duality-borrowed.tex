
% Copyright 2022 by Robert Hildebrand
%This work is licensed under a
%Creative Commons Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)
%See http://creativecommons.org/licenses/by-sa/4.0/

% this was borrowed from \url{https://www.cs.purdue.edu/homes/egrigore/580FT15/26-lp-jefferickson.pdf}
%26.5 Duality Example
Before I prove the stronger duality theorem, let me first provide some intuition about where this duality thing comes from in the first place. ${ }^{6}$ Consider the following linear programming problem:
\begin{align*}
\text { maximize } & 
4 x_{1}+x_{2}+3 x_{3} \\
\text { subject to } \quad x_{1}+4 x_{2} & \leq 2 \\
& 3 x_{1}-x_{2}+x_{3} & \leq 4 \\
& x_{1}, x_{2}, x_{3} & \geq 0
\end{align*}
Let $\sigma^{*}$ denote the optimum objective value for this LP. The feasible solution $x=(1,0,0)$ gives us a lower bound $\sigma^{*} \geq 4$. A different feasible solution $x=(0,0,3)$ gives us a better lower bound $\sigma^{*} \geq 9$. We could play this game all day, finding different feasible solutions and getting ever larger lower bounds. How do we know when we're done? Is there a way to prove an upper bound on $\sigma^{*}$ ?

In fact, there is. Let's multiply each of the constraints in our LP by a new non-negative scalar value $y_{i}$ :
$$
\begin{aligned}
\text { maximize } 4 x_{1}+x_{2}+3 x_{3} & \\
\text { subject to } y_{1}\left(x_{1}+4 x_{2} \quad\right.& \leq 2 y_{1} \\
y_{2}\left(3 x_{1}-x_{2}+x_{3}\right) & \leq 4 y_{2} \\
x_{1}, x_{2}, x_{3} & \geq 0
\end{aligned}
$$
Because each $y_{i}$ is non-negative, we do not reverse any of the inequalities. Any feasible solution $\left(x_{1}, x_{2}, x_{3}\right)$ must satisfy both of these inequalities, so it must also satisfy their sum:
$$
\left(y_{1}+3 y_{2}\right) x_{1}+\left(4 y_{1}-y_{2}\right) x_{2}+y_{2} x_{3} \leq 2 y_{1}+4 y_{2} \text {. }
$$
Now suppose that each $y_{i}$ is larger than the $i$ th coefficient of the objective function:
$$
y_{1}+3 y_{2} \geq 4, \quad 4 y_{1}-y_{2} \geq 1, \quad y_{2} \geq 3 \text {. }
$$
This assumption lets us derive an upper bound on the objective value of any feasible solution:
$$
4 x_{1}+x_{2}+3 x_{3} \leq\left(y_{1}+3 y_{2}\right) x_{1}+\left(4 y_{1}-y_{2}\right) x_{2}+y_{2} x_{3} \leq 2 y_{1}+4 y_{2} .
$$
In particular, by plugging in the optimal solution $\left(x_{1}^{*}, x_{2}^{*}, x_{3}^{*}\right)$ for the original LP, we obtain the following upper bound on $\sigma^{*}$ :
$$
\sigma^{*}=4 x_{1}^{*}+x_{2}^{*}+3 x_{3}^{*} \leq 2 y_{1}+4 y_{2} .
$$
Now it's natural to ask how tight we can make this upper bound. How small can we make the expression $2 y_{1}+4 y_{2}$ without violating any of the inequalities we used to prove the upper bound? This is just another linear programming problem.
$$
\begin{array}{rr}
\text { minimize } & 2 y_{1}+4 y_{2} \\
\text { subject to } & y_{1}+3 y_{2} \geq 4 \\
& 4 y_{1}-y_{2} \geq 1 \\
y_{2} & \geq 3 \\
y_{1}, y_{2} & \geq 0
\end{array}
$$
"This example is taken from Robert Vanderbei's excellent textbook Linear Programming: Foundations and Extensions [Springer, 2001], but the idea appears earlier in Jens Clausen's 1997 paper 'Teaching Duality in Linear Programming: The Multiplier Approach'.

\url{https://www.cs.purdue.edu/homes/egrigore/580FT15/26-lp-jefferickson.pdf}
